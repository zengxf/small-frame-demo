import torch
import torch.nn.functional as F
import torch.nn as nn
from model import ResUNetSegmentation
from dataset import SegmentationDataset  # ä¿®æ”¹ä¸ºä½¿ç”¨SegmentationDataset
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import ExponentialLR
from tqdm import tqdm
import matplotlib.pyplot as plt
import os
from torchvision import transforms
import numpy as np


class FocalLoss(nn.Module):
    def __init__(self, alpha=0.9, gamma=2.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, logits, labels):
        BCE_loss = F.binary_cross_entropy_with_logits(logits, labels, reduction='none')
        pt = torch.sigmoid(logits)
        pt = torch.where(labels == 1, pt, 1 - pt)
        focal_weight = (1 - pt) ** self.gamma
        alpha_t = self.alpha * labels + (1 - self.alpha) * (1 - labels)
        loss = alpha_t * focal_weight * BCE_loss
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss


def compute_miou(preds, labels, num_classes=2):
    """
    è®¡ç®— mIoUï¼ˆMean Intersection over Unionï¼‰

    Args:
        preds: é¢„æµ‹ç»“æœ [B, 1, H, W]ï¼Œé€šè¿‡ sigmoid å¾—åˆ°çš„äºŒå€¼åŒ–é¢„æµ‹
        labels: çœŸå®æ ‡ç­¾ [B, 1, H, W]
        num_classes: ç±»åˆ«æ•°é‡ï¼Œé»˜è®¤ä¸º 2 ç±»ï¼ˆå‰æ™¯å’ŒèƒŒæ™¯ï¼‰

    Returns:
        miou: å¹³å‡äº¤å¹¶æ¯”ï¼ˆmIoUï¼‰
    """
    # å°†é¢„æµ‹å’Œæ ‡ç­¾è½¬æ¢ä¸ºäºŒå€¼åŒ–ç»“æœ
    preds = (torch.sigmoid(preds) > 0.5).float()
    labels = labels.float()

    # åˆå§‹åŒ–äº¤é›†å’Œå¹¶é›†
    intersection = torch.zeros(num_classes).to(preds.device)
    union = torch.zeros(num_classes).to(preds.device)

    for i in range(num_classes):
        # å½“å‰ç±»åˆ«çš„é¢„æµ‹å’Œæ ‡ç­¾
        pred_i = (preds == i).float()
        label_i = (labels == i).float()

        # è®¡ç®—äº¤é›†å’Œå¹¶é›†
        intersection[i] = (pred_i * label_i).sum()
        union[i] = pred_i.sum() + label_i.sum() - intersection[i]

    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ IoU
    iou = intersection / (union + 1e-6)  # é˜²æ­¢é™¤ä»¥é›¶
    miou = iou.mean()  # mIoU æ˜¯æ‰€æœ‰ç±»åˆ« IoU çš„å¹³å‡å€¼

    return miou.item()


if __name__ == "__main__":
    EPOCHS = 55
    BATCH_SIZE = 4
    LEARNING_RATE = 1e-4
    DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    MODEL_SAVE_PATH = "./checkpoints"
    os.makedirs(MODEL_SAVE_PATH, exist_ok=True)
    WEIGHTED_LOSS = False
    USE_FOCAL_LOSS = True  # ä½¿ç”¨ Focal Loss
    GAMMA = 2.0  # Focal Loss å‚æ•°
    ALPHA = 0.9  # Focal Loss æ­£æ ·æœ¬æƒé‡
    IMG_SIZE = (480, 640)
    NUM_CLASSES = 2

    # model = ResUNetSegmentation()
    model = ResUNetSegmentation()
    model = model.to(DEVICE)

    # æ•°æ®è·¯å¾„ - ä¿®æ”¹ä¸ºä½¿ç”¨å›¾åƒå’Œmaskåˆ†å¼€çš„è·¯å¾„
    train_img_dir = r'F:\3DVideo\Unet\imgs\train_img'
    train_mask_dir = r'F:\3DVideo\Unet\imgs\train_mask'
    val_img_dir = r'F:\3DVideo\Unet\imgs\val_img'
    val_mask_dir = r'F:\3DVideo\Unet\imgs\val_mask'

    # åˆ›å»º dataset å’Œ dataloader - ä½¿ç”¨SegmentationDataset
    train_dataset = SegmentationDataset(
        data_dir=train_img_dir,
        mask_dir=train_mask_dir,
        output_size=IMG_SIZE,
        num_classes=NUM_CLASSES
    )
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

    val_dataset = SegmentationDataset(
        data_dir=val_img_dir,
        mask_dir=val_mask_dir,
        output_size=IMG_SIZE,
        num_classes=NUM_CLASSES
    )
    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    # è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰
    class_weights = train_dataset.get_class_weights().to(DEVICE)
    print(f"ç±»åˆ«æƒé‡: {class_weights}")

    checkpoint_path = os.path.join(MODEL_SAVE_PATH, "best_model.pth")
    start_epoch = 0
    best_val_miou = 0.0  # æ”¹ä¸º best_val_miou æ›´å‡†ç¡®
    best_val_loss = float('inf')
    current_lr = LEARNING_RATE

    if os.path.exists(checkpoint_path):
        print(f"åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
        model.load_state_dict(checkpoint['model_state_dict'])
        best_val_miou = checkpoint['best_val_miou']
        best_val_loss = checkpoint['best_val_loss']
        current_lr = checkpoint.get('current_lr', LEARNING_RATE)
        start_epoch = checkpoint.get('epoch', 0)
        print(f"æ¢å¤ epoch={start_epoch}, mIoU={best_val_miou:.4f}, loss={best_val_loss:.4f}, lr={current_lr}")

    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(model.parameters(), lr=current_lr, weight_decay=0.0005)

    # å­¦ä¹ ç‡è¡°å‡ï¼šæ¯ epoch è¡°å‡ä¸€æ¬¡
    scheduler = ExponentialLR(optimizer, gamma=0.98)

    # æŸå¤±å‡½æ•°
    if USE_FOCAL_LOSS:
        criterion = FocalLoss(alpha=ALPHA, gamma=GAMMA, reduction='mean').to(DEVICE)
    elif WEIGHTED_LOSS:
        # ä½¿ç”¨è®¡ç®—å¾—åˆ°çš„ç±»åˆ«æƒé‡
        criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])  # å‡è®¾ç±»åˆ«1æ˜¯æ­£æ ·æœ¬
    else:
        criterion = nn.BCEWithLogitsLoss()

    train_losses = []
    train_mious = []  # æ”¹ä¸º mious æ›´å‡†ç¡®
    val_losses = []
    val_mious = []  # æ”¹ä¸º mious æ›´å‡†ç¡®

    for epoch in range(start_epoch, EPOCHS):
        print(f"\n{'=' * 50}")
        print(f"EPOCH {epoch + 1}/{EPOCHS}")

        model.train()
        epoch_train_loss = 0.0
        epoch_train_miou = 0.0  # mIoU åˆå§‹åŒ–
        train_loop = tqdm(train_dataloader, desc="Training")
        for batch_idx, (images, masks) in enumerate(train_loop):
            images = images.to(DEVICE)  # [B, 1, 480, 640]
            masks = masks.to(DEVICE).unsqueeze(1)  # [4, 480, 640]

            optimizer.zero_grad()
            outputs = model(images)  # [B, 1, 480, 640]

            # è®¡ç®—æŸå¤±
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()

            # ç´¯åŠ æŸå¤±
            epoch_train_loss += loss.item() * images.size(0)

            # è®¡ç®— mIoU
            with torch.no_grad():
                miou = compute_miou(outputs, masks)
                epoch_train_miou += miou * images.size(0)  # ä¹˜ä»¥batch size

            # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
            train_loop.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'mIoU': f'{miou:.4f}'
            })

        # è®¡ç®— epoch å¹³å‡æŒ‡æ ‡
        avg_train_loss = epoch_train_loss / len(train_dataset)
        avg_train_miou = epoch_train_miou / len(train_dataset)  # é™¤ä»¥æ€»æ ·æœ¬æ•°
        train_losses.append(avg_train_loss)
        train_mious.append(avg_train_miou)

        print(f"Train Loss: {avg_train_loss:.6f}, mIoU: {avg_train_miou:.4f}")

        # --- éªŒè¯é˜¶æ®µ ---
        model.eval()
        epoch_val_loss = 0.0
        epoch_val_miou = 0.0  # mIoU åˆå§‹åŒ–

        val_loop = tqdm(val_dataloader, desc="Validating")
        with torch.no_grad():
            for batch_idx, (images, masks) in enumerate(val_loop):
                images = images.to(DEVICE)
                masks = masks.to(DEVICE).unsqueeze(1)
                outputs = model(images)  # [B, 1, 480, 640]

                loss = criterion(outputs, masks)
                epoch_val_loss += loss.item() * images.size(0)

                # è®¡ç®— mIoU
                miou = compute_miou(outputs, masks)
                epoch_val_miou += miou * images.size(0)  # ä¹˜ä»¥batch size

                # æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                val_loop.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'mIoU': f'{miou:.4f}'
                })

        # è®¡ç®— epoch å¹³å‡æŒ‡æ ‡
        avg_val_loss = epoch_val_loss / len(val_dataset)
        avg_val_miou = epoch_val_miou / len(val_dataset)  # é™¤ä»¥æ€»æ ·æœ¬æ•°
        val_losses.append(avg_val_loss)
        val_mious.append(avg_val_miou)

        print(f"Val Loss: {avg_val_loss:.6f}, mIoU: {avg_val_miou:.4f}")

        # --- å­¦ä¹ ç‡æ›´æ–° ---
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Current LR: {current_lr:.6e}")

        # --- ä¿å­˜æœ€ä½³æ¨¡å‹ ---
        if avg_val_miou > best_val_miou:  # ä½¿ç”¨ mIoU ä½œä¸ºè¯„ä¼°æ ‡å‡†
            best_val_miou = avg_val_miou
            best_val_loss = avg_val_loss
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'best_val_miou': best_val_miou,  # æ”¹ä¸º mIoU
                'best_val_loss': best_val_loss,
                'train_losses': train_losses,
                'val_losses': val_losses,
                'train_mious': train_mious,  # æ”¹ä¸º mious
                'val_mious': val_mious,  # æ”¹ä¸º mious
                'class_weights': class_weights.cpu()  # ä¿å­˜ç±»åˆ«æƒé‡
            }
            save_path = os.path.join(MODEL_SAVE_PATH, "best_model.pth")
            torch.save(checkpoint, save_path)
            print(f"âœ… Best model saved! mIoU: {best_val_miou:.4f}, Loss: {best_val_loss:.6f}")

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 10 == 0:
            checkpoint_path = os.path.join(MODEL_SAVE_PATH, f"checkpoint_epoch_{epoch + 1}.pth")
            torch.save(checkpoint, checkpoint_path)
            print(f"ğŸ“ Checkpoint saved at epoch {epoch + 1}")

    # -------------------------------
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    # -------------------------------
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss Curve')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(train_mious, label='Train mIoU')
    plt.plot(val_mious, label='Val mIoU')
    plt.xlabel('Epoch')
    plt.ylabel('mIoU')
    plt.title('mIoU Curve')
    plt.legend()

    plt.tight_layout()
    plt.savefig('training_validation_curve.png')
    plt.show()

    print("âœ… è®­ç»ƒå®Œæˆï¼Œæ›²çº¿å·²ä¿å­˜ã€‚")